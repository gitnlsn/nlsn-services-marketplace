<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Storage Services - Backend Services</title>
    <link rel="stylesheet" href="../styles.css">
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';
        mermaid.initialize({ startOnLoad: true });
    </script>
</head>
<body>
    <div class="container">
        <div class="breadcrumb">
            <a href="../index.html">Home</a>
            <span class="breadcrumb-separator">‚Ä∫</span>
            <a href="./index.html">Backend Services</a>
            <span class="breadcrumb-separator">‚Ä∫</span>
            <span>Storage Services</span>
        </div>

        <h1>Storage Services</h1>
        
        <div class="alert alert-info">
            <strong>Overview:</strong> Multi-provider file storage system with AWS S3, Google Drive integration, and unified storage abstraction layer.
        </div>

        <h2>Storage Architecture</h2>
        <div class="mermaid">
        graph TB
            Client[Client Upload] --> Unified[Unified Storage Service]
            Unified --> Router{Storage Router}
            
            Router -->|Primary| S3[AWS S3 Service]
            Router -->|Backup| GDrive[Google Drive Service]
            Router -->|Local Dev| Local[Local Storage]
            
            S3 --> AWS[AWS S3 Bucket]
            GDrive --> GoogleAPI[Google Drive API]
            Local --> FileSystem[Local File System]
            
            AWS --> CDN[CloudFront CDN]
            CDN --> GlobalAccess[Global Access]
            
            Unified --> Database[(File Metadata)]
            Database --> Analytics[Storage Analytics]
            
            style Client fill:#ADD8E6
            style Unified fill:#FFD700
            style Router fill:#DDA0DD
            style GlobalAccess fill:#C8E6C9
        </div>

        <h2>Storage Providers</h2>
        <div class="grid-3">
            <div class="card">
                <h3 class="gradient-text">‚òÅÔ∏è AWS S3</h3>
                <ul>
                    <li>Primary storage provider</li>
                    <li>Infinite scalability</li>
                    <li>Global CDN distribution</li>
                    <li>99.999999999% durability</li>
                    <li>Cost-effective at scale</li>
                </ul>
            </div>
            <div class="card">
                <h3 class="gradient-text">üìÅ Google Drive</h3>
                <ul>
                    <li>Backup storage option</li>
                    <li>Collaborative features</li>
                    <li>Built-in sharing controls</li>
                    <li>Document processing</li>
                    <li>Version control</li>
                </ul>
            </div>
            <div class="card">
                <h3 class="gradient-text">üíæ Local Storage</h3>
                <ul>
                    <li>Development environment</li>
                    <li>Testing and debugging</li>
                    <li>Quick local access</li>
                    <li>No external dependencies</li>
                    <li>Cost-free for development</li>
                </ul>
            </div>
        </div>

        <h2>Unified Storage Interface</h2>
        <div class="code-section">
            <div class="code-header">
                <span>TypeScript - Storage Interface</span>
                <span class="code-language">TS</span>
            </div>
            <pre><code>// Unified storage interface
export interface StorageProvider {
  upload(file: File, path: string, options?: UploadOptions): Promise&lt;UploadResult&gt;;
  download(path: string): Promise&lt;Buffer&gt;;
  delete(path: string): Promise&lt;void&gt;;
  getUrl(path: string, expiresIn?: number): Promise&lt;string&gt;;
  copy(source: string, destination: string): Promise&lt;void&gt;;
  move(source: string, destination: string): Promise&lt;void&gt;;
  exists(path: string): Promise&lt;boolean&gt;;
  getMetadata(path: string): Promise&lt;FileMetadata&gt;;
}

// Upload configuration
interface UploadOptions {
  contentType?: string;
  public?: boolean;
  metadata?: Record&lt;string, string&gt;;
  encryption?: boolean;
  thumbnail?: boolean;
  compress?: boolean;
}

interface UploadResult {
  path: string;
  url: string;
  size: number;
  contentType: string;
  etag?: string;
  provider: 'aws-s3' | 'google-drive' | 'local';
}

// Unified storage service implementation
export class UnifiedStorageService implements StorageProvider {
  private primaryProvider: StorageProvider;
  private backupProvider?: StorageProvider;
  private localProvider?: StorageProvider;
  
  constructor(config: StorageConfig) {
    this.primaryProvider = new S3StorageService(config.aws);
    this.backupProvider = config.googleDrive ? new GoogleDriveService(config.googleDrive) : undefined;
    this.localProvider = config.local ? new LocalStorageService(config.local) : undefined;
  }

  async upload(file: File, path: string, options: UploadOptions = {}): Promise&lt;UploadResult&gt; {
    try {
      // Primary upload
      const result = await this.primaryProvider.upload(file, path, options);
      
      // Optional backup upload
      if (this.backupProvider && options.backup) {
        await this.backupProvider.upload(file, path, options).catch(err => {
          console.warn('Backup upload failed:', err);
        });
      }
      
      // Store metadata in database
      await this.storeFileMetadata({
        path: result.path,
        originalName: file.name,
        size: result.size,
        contentType: result.contentType,
        provider: result.provider,
        uploadedAt: new Date()
      });
      
      return result;
    } catch (error) {
      console.error('Upload failed:', error);
      throw new Error('File upload failed');
    }
  }
}</code></pre>
        </div>

        <h2>AWS S3 Service Implementation</h2>
        <div class="code-section">
            <div class="code-header">
                <span>TypeScript - S3 Service</span>
                <span class="code-language">TS</span>
            </div>
            <pre><code>import { S3Client, PutObjectCommand, GetObjectCommand, DeleteObjectCommand } from "@aws-sdk/client-s3";
import { getSignedUrl } from "@aws-sdk/s3-request-presigner";

export class S3StorageService implements StorageProvider {
  private s3Client: S3Client;
  private bucketName: string;
  private region: string;
  private cloudFrontDomain?: string;

  constructor(config: S3Config) {
    this.s3Client = new S3Client({
      region: config.region,
      credentials: {
        accessKeyId: config.accessKeyId,
        secretAccessKey: config.secretAccessKey
      }
    });
    this.bucketName = config.bucketName;
    this.region = config.region;
    this.cloudFrontDomain = config.cloudFrontDomain;
  }

  async upload(file: File, path: string, options: UploadOptions = {}): Promise&lt;UploadResult&gt; {
    const buffer = Buffer.from(await file.arrayBuffer());
    
    // Generate optimized path
    const optimizedPath = this.generatePath(path, file.name);
    
    // Prepare upload parameters
    const uploadParams = {
      Bucket: this.bucketName,
      Key: optimizedPath,
      Body: buffer,
      ContentType: options.contentType || file.type,
      Metadata: options.metadata || {},
      ServerSideEncryption: options.encryption ? 'AES256' : undefined,
      ACL: options.public ? 'public-read' : 'private'
    };

    try {
      const command = new PutObjectCommand(uploadParams);
      const response = await this.s3Client.send(command);
      
      // Generate public URL
      const url = this.generatePublicUrl(optimizedPath, options.public);
      
      return {
        path: optimizedPath,
        url,
        size: buffer.length,
        contentType: file.type,
        etag: response.ETag,
        provider: 'aws-s3'
      };
    } catch (error) {
      console.error('S3 upload error:', error);
      throw new Error('Failed to upload to S3');
    }
  }

  async getSignedUrl(path: string, expiresIn: number = 3600): Promise&lt;string&gt; {
    const command = new GetObjectCommand({
      Bucket: this.bucketName,
      Key: path
    });
    
    return await getSignedUrl(this.s3Client, command, { expiresIn });
  }

  private generatePath(basePath: string, filename: string): string {
    const timestamp = Date.now();
    const randomString = Math.random().toString(36).substring(2);
    const extension = filename.split('.').pop();
    
    return `${basePath}/${timestamp}-${randomString}.${extension}`;
  }

  private generatePublicUrl(path: string, isPublic: boolean): string {
    if (this.cloudFrontDomain && isPublic) {
      return `https://${this.cloudFrontDomain}/${path}`;
    }
    return `https://${this.bucketName}.s3.${this.region}.amazonaws.com/${path}`;
  }
}</code></pre>
        </div>

        <h2>Google Drive Service Implementation</h2>
        <div class="code-section">
            <div class="code-header">
                <span>TypeScript - Google Drive Service</span>
                <span class="code-language">TS</span>
            </div>
            <pre><code>import { google } from 'googleapis';

export class GoogleDriveService implements StorageProvider {
  private drive: any;
  private rootFolderId: string;

  constructor(config: GoogleDriveConfig) {
    const auth = new google.auth.GoogleAuth({
      keyFile: config.serviceAccountKeyFile,
      scopes: ['https://www.googleapis.com/auth/drive.file']
    });
    
    this.drive = google.drive({ version: 'v3', auth });
    this.rootFolderId = config.rootFolderId;
  }

  async upload(file: File, path: string, options: UploadOptions = {}): Promise&lt;UploadResult&gt; {
    try {
      // Create folder structure if needed
      const folderId = await this.ensureFolderStructure(path);
      
      // Upload file
      const response = await this.drive.files.create({
        requestBody: {
          name: file.name,
          parents: [folderId],
          mimeType: file.type
        },
        media: {
          mimeType: file.type,
          body: Buffer.from(await file.arrayBuffer())
        }
      });

      // Set permissions if public
      if (options.public) {
        await this.drive.permissions.create({
          fileId: response.data.id,
          requestBody: {
            role: 'reader',
            type: 'anyone'
          }
        });
      }

      const publicUrl = options.public 
        ? `https://drive.google.com/file/d/${response.data.id}/view`
        : `https://drive.google.com/file/d/${response.data.id}`;

      return {
        path: `${path}/${file.name}`,
        url: publicUrl,
        size: file.size,
        contentType: file.type,
        provider: 'google-drive'
      };
    } catch (error) {
      console.error('Google Drive upload error:', error);
      throw new Error('Failed to upload to Google Drive');
    }
  }

  async download(path: string): Promise&lt;Buffer&gt; {
    try {
      const fileId = await this.getFileIdByPath(path);
      const response = await this.drive.files.get({
        fileId,
        alt: 'media'
      });
      
      return Buffer.from(response.data);
    } catch (error) {
      console.error('Google Drive download error:', error);
      throw new Error('Failed to download from Google Drive');
    }
  }

  private async ensureFolderStructure(path: string): Promise&lt;string&gt; {
    const parts = path.split('/').filter(part => part.length > 0);
    let currentFolderId = this.rootFolderId;

    for (const part of parts) {
      // Check if folder exists
      const existingFolder = await this.findFolder(part, currentFolderId);
      
      if (existingFolder) {
        currentFolderId = existingFolder.id;
      } else {
        // Create folder
        const newFolder = await this.drive.files.create({
          requestBody: {
            name: part,
            mimeType: 'application/vnd.google-apps.folder',
            parents: [currentFolderId]
          }
        });
        currentFolderId = newFolder.data.id;
      }
    }

    return currentFolderId;
  }
}</code></pre>
        </div>

        <h2>File Upload Router</h2>
        <div class="code-section">
            <div class="code-header">
                <span>TypeScript - Upload Router</span>
                <span class="code-language">TS</span>
            </div>
            <pre><code>export const uploadRouter = createTRPCRouter({
  getUploadUrl: protectedProcedure
    .input(z.object({
      filename: z.string(),
      contentType: z.string(),
      folder: z.enum(['profile', 'service', 'portfolio', 'documents']),
      public: z.boolean().default(false)
    }))
    .mutation(async ({ ctx, input }) => {
      const storageService = createUnifiedStorageService();
      
      // Generate presigned URL for direct upload
      const uploadUrl = await storageService.getPresignedUploadUrl({
        filename: input.filename,
        contentType: input.contentType,
        folder: input.folder,
        userId: ctx.session.user.id,
        public: input.public
      });
      
      return {
        uploadUrl,
        path: uploadUrl.path,
        expiresIn: 3600 // 1 hour
      };
    }),

  confirmUpload: protectedProcedure
    .input(z.object({
      path: z.string(),
      filename: z.string(),
      size: z.number(),
      contentType: z.string()
    }))
    .mutation(async ({ ctx, input }) => {
      // Verify upload and store metadata
      const fileRecord = await ctx.db.fileUpload.create({
        data: {
          path: input.path,
          filename: input.filename,
          size: input.size,
          contentType: input.contentType,
          uploadedBy: ctx.session.user.id,
          status: 'completed'
        }
      });
      
      return {
        id: fileRecord.id,
        url: await storageService.getPublicUrl(input.path)
      };
    }),

  deleteFile: protectedProcedure
    .input(z.object({
      fileId: z.string()
    }))
    .mutation(async ({ ctx, input }) => {
      const file = await ctx.db.fileUpload.findUnique({
        where: { id: input.fileId }
      });
      
      if (!file || file.uploadedBy !== ctx.session.user.id) {
        throw new TRPCError({ code: 'NOT_FOUND' });
      }
      
      const storageService = createUnifiedStorageService();
      await storageService.delete(file.path);
      
      await ctx.db.fileUpload.update({
        where: { id: input.fileId },
        data: { status: 'deleted', deletedAt: new Date() }
      });
      
      return { success: true };
    })
});</code></pre>
        </div>

        <h2>File Processing Pipeline</h2>
        <div class="mermaid">
        graph LR
            Upload[File Upload] --> Validate[Validation]
            Validate -->|Valid| Process[Processing Pipeline]
            Validate -->|Invalid| Reject[Reject Upload]
            
            Process --> Resize[Image Resize]
            Process --> Compress[Compression]
            Process --> Thumbnail[Thumbnail Generation]
            Process --> Scan[Virus Scan]
            
            Resize --> Store[Store Processed]
            Compress --> Store
            Thumbnail --> Store
            Scan -->|Clean| Store
            Scan -->|Infected| Quarantine[Quarantine]
            
            Store --> CDN[CDN Distribution]
            Store --> Backup[Backup Storage]
            
            CDN --> Complete[Upload Complete]
            Backup --> Complete
            
            style Upload fill:#ADD8E6
            style Validate fill:#FFD700
            style Process fill:#DDA0DD
            style Complete fill:#C8E6C9
            style Reject fill:#FFCDD2
            style Quarantine fill:#FFCDD2
        </div>

        <h2>File Processing Features</h2>
        <div class="grid-2">
            <div class="card">
                <h3>Image Processing</h3>
                <ul>
                    <li><strong>Resize:</strong> Multiple sizes for different use cases</li>
                    <li><strong>Compress:</strong> Optimize file size without quality loss</li>
                    <li><strong>Thumbnails:</strong> Generate preview images</li>
                    <li><strong>Format Conversion:</strong> WebP for modern browsers</li>
                    <li><strong>Watermarking:</strong> Brand protection for portfolios</li>
                </ul>
            </div>
            <div class="card">
                <h3>Security & Validation</h3>
                <ul>
                    <li><strong>File Type Validation:</strong> Whitelist allowed formats</li>
                    <li><strong>Size Limits:</strong> Prevent oversized uploads</li>
                    <li><strong>Virus Scanning:</strong> ClamAV integration</li>
                    <li><strong>Content Filtering:</strong> Inappropriate content detection</li>
                    <li><strong>Access Control:</strong> Role-based file access</li>
                </ul>
            </div>
        </div>

        <h2>Storage Configuration</h2>
        <table class="config-table">
            <thead>
                <tr>
                    <th>File Type</th>
                    <th>Max Size</th>
                    <th>Allowed Formats</th>
                    <th>Processing</th>
                    <th>Storage Tier</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td>Profile Images</td>
                    <td>5MB</td>
                    <td>JPG, PNG, WebP</td>
                    <td>Resize, Compress</td>
                    <td>S3 Standard</td>
                </tr>
                <tr>
                    <td>Service Photos</td>
                    <td>10MB</td>
                    <td>JPG, PNG, WebP</td>
                    <td>Multiple sizes, Watermark</td>
                    <td>S3 Standard + CDN</td>
                </tr>
                <tr>
                    <td>Documents</td>
                    <td>25MB</td>
                    <td>PDF, DOC, DOCX</td>
                    <td>Virus scan, Preview</td>
                    <td>S3 IA (Infrequent Access)</td>
                </tr>
                <tr>
                    <td>Portfolio Videos</td>
                    <td>100MB</td>
                    <td>MP4, MOV, AVI</td>
                    <td>Compress, Thumbnail</td>
                    <td>S3 Standard + CDN</td>
                </tr>
                <tr>
                    <td>Backup Files</td>
                    <td>1GB</td>
                    <td>ZIP, TAR, RAR</td>
                    <td>Virus scan only</td>
                    <td>S3 Glacier</td>
                </tr>
            </tbody>
        </table>

        <h2>CDN Integration</h2>
        <div class="card">
            <h3>CloudFront Configuration</h3>
            <ul>
                <li><strong>Global Distribution:</strong> Edge locations worldwide for fast access</li>
                <li><strong>Cache Optimization:</strong> Long TTL for static assets</li>
                <li><strong>Compression:</strong> Automatic gzip/brotli compression</li>
                <li><strong>Security Headers:</strong> CORS, CSP, and security headers</li>
                <li><strong>Image Optimization:</strong> On-the-fly image format conversion</li>
                <li><strong>Bandwidth Optimization:</strong> Smart compression and caching</li>
            </ul>
        </div>

        <h2>Storage Analytics</h2>
        <div class="feature-list">
            <li><strong>Usage Metrics:</strong> Storage consumption by user/service type</li>
            <li><strong>Cost Analysis:</strong> Storage costs breakdown by provider</li>
            <li><strong>Performance Monitoring:</strong> Upload/download speed tracking</li>
            <li><strong>Error Tracking:</strong> Failed uploads and error analysis</li>
            <li><strong>Bandwidth Usage:</strong> CDN and direct access metrics</li>
            <li><strong>Popular Content:</strong> Most accessed files and trends</li>
        </div>

        <h2>Backup & Disaster Recovery</h2>
        <div class="alert alert-success">
            <strong>Data Protection Strategy:</strong>
            <ul>
                <li><strong>Multi-Region Replication:</strong> S3 cross-region backup</li>
                <li><strong>Versioning:</strong> Keep multiple versions of important files</li>
                <li><strong>Point-in-Time Recovery:</strong> Restore files to specific timestamps</li>
                <li><strong>Automated Backups:</strong> Daily incremental backups to Google Drive</li>
                <li><strong>Disaster Recovery Testing:</strong> Regular recovery procedure validation</li>
                <li><strong>Data Integrity Checks:</strong> Periodic file integrity verification</li>
            </ul>
        </div>

        <h2>Integration Points</h2>
        <ul>
            <li><strong>User Service:</strong> Profile image uploads and management</li>
            <li><strong>Service Management:</strong> Service photos and portfolio files</li>
            <li><strong>Document Verification:</strong> ID and license document storage</li>
            <li><strong>Messaging System:</strong> File attachments in conversations</li>
            <li><strong>Review System:</strong> Photo evidence in reviews and disputes</li>
            <li><strong>Admin Tools:</strong> System backups and maintenance files</li>
        </ul>
    </div>
</body>
</html>